# -*- coding: utf-8 -*-
"""Capstone Test 3_V10(Using polygon+Exit early =False)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15dRPS7aENXRsKcvpWWcM_ktmETeptLwA

Cell 1 â€” å®‰è£ / åŒ¯å…¥ / å…¨åŸŸè¨­å®šï¼ˆå«åŠ é€Ÿåƒæ•¸èˆ‡ HTTP é€£ç·šæ± ï¼‰
"""

# (å¯çœç•¥) !pip install -q pandas requests python-dateutil

import os, time, warnings, requests, pandas as pd
from datetime import datetime, date, timedelta
from dateutil.relativedelta import relativedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import OrderedDict
from functools import lru_cache
from typing import Dict, Tuple, Optional
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter

warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

# ===== åŸºæœ¬è¨­å®š =====
API_KEY = os.getenv("POLYGON_API_KEY", "J_wZYB3rGZBaFv2tdyg21X1vmVXrMW21").strip()
assert API_KEY and all(ord(c) < 128 for c in API_KEY), "API_KEY ç„¡æ•ˆæˆ–å«é ASCII"
BASE = "https://api.polygon.io"

TARGET_YEAR = datetime.today().year - 1       # å¹´åº¦å°æ¯”ç”¨ï¼šå»å¹´çš„ Q4
YIELD_MIN, YIELD_MAX = 3.0, 10.0              # æ®–åˆ©ç‡ç¯©é¸ï¼ˆç™¾åˆ†æ¯”ï¼‰
MAX_WORKERS = 16                               # ä½µç™¼ï¼ˆè¦–é…é¡èª¿æ•´ï¼‰

# ===== åŠ é€Ÿé¸é … =====
FAST_EARLY_EXIT = False        # ä¸€æ—¦ç¢ºå®šä¸åˆæ ¼å°±ä¸åšå¾ŒçºŒé‡å·¥ï¼ˆæ¬„ä½ä»é½Šå…¨ä½†å¤šç‚º Noneï¼‰
LOOKBACK_YEARS_DIV = 3        # è‚¡åˆ©å›æœ”å¹´æ•¸ï¼ˆè¶³å¤  TTM/7å­£/3å¹´æ¬¡æ•¸ï¼‰
LOOKBACK_YEARS_BS  = 3        # Balance Sheet å›æœ”å¹´æ•¸
LOOKBACK_YEARS_EPS = 5        # EPS å›æœ”å¹´æ•¸ï¼ˆæœ€å¤š 16 å­£ï¼‰

# ===== HTTP Sessionï¼ˆé€£ç·šæ±  + é‡è©¦ï¼‰=====
SESSION = requests.Session()
retries = Retry(total=2, backoff_factor=0.3, status_forcelist=[429, 500, 502, 503, 504])
adapter = HTTPAdapter(pool_connections=128, pool_maxsize=128, max_retries=retries)
SESSION.mount("https://", adapter); SESSION.mount("http://", adapter)

# å¥æª¢
r = SESSION.get(f"{BASE}/v3/reference/tickers", params={"limit":1,"apiKey":API_KEY}, timeout=15)
r.raise_for_status()
print(f"âœ… Polygon API OK | TARGET_YEAR={TARGET_YEAR}")

"""Cell 2 â€” å…±ç”¨ï¼šHTTP å·¥å…·ã€Ticker åˆ—è¡¨ / åƒè€ƒè³‡æ–™ / åƒ¹æ ¼ã€å¸‚å€¼åˆ†é¡"""

def _get(url, params=None, retry=2, sleep=0.25):
    params = dict(params or {}); params["apiKey"] = API_KEY
    last = None
    for _ in range(retry+1):
        try:
            r = SESSION.get(url, params=params, timeout=30)
            r.raise_for_status()
            js = r.json()
            if isinstance(js, dict) and js.get("status") == "ERROR":
                raise RuntimeError(js.get("error") or "Polygon API error")
            return js
        except Exception as e:
            last = e; time.sleep(sleep)
    raise last

def _paged(url, params=None):
    params = dict(params or {}); params["apiKey"] = API_KEY
    out = []
    r = SESSION.get(url, params=params, timeout=30); r.raise_for_status()
    js = r.json()
    if isinstance(js, dict) and js.get("status") == "ERROR":
        raise RuntimeError(js.get("error") or "Polygon API error")
    out += js.get("results", []) or []
    while js.get("next_url"):
        nxt = js["next_url"]; base = nxt.split("?")[0]
        qs = nxt.split("?")[1] if "?" in nxt else ""; p2={}
        for kv in qs.split("&"):
            if not kv or kv.startswith("apiKey="): continue
            k, v = kv.split("=", 1); p2[k] = v
        p2["apiKey"] = API_KEY
        r = SESSION.get(base, params=p2, timeout=30); r.raise_for_status()
        js = r.json()
        if isinstance(js, dict) and js.get("status") == "ERROR":
            raise RuntimeError(js.get("error") or "Polygon API error")
        out += js.get("results", []) or []
    return out

def _to_date(s):
    try: return pd.to_datetime(s).date()
    except: return None

@lru_cache(maxsize=1_000)
def fetch_all_us_common():
    url = f"{BASE}/v3/reference/tickers"
    params={"market":"stocks","type":"CS","active":"true","locale":"us","limit":1000,"sort":"ticker"}
    out=[]
    while True:
        js=_get(url,params); out += [x["ticker"] for x in js.get("results",[]) if x.get("ticker")]
        nxt=js.get("next_url")
        if not nxt: break
        url=nxt.split("?")[0]
        params={kv.split("=")[0]:kv.split("=")[1] for kv in nxt.split("?")[1].split("&") if not kv.startswith("apiKey=")}
    return out

@lru_cache(maxsize=10_000)
def get_ref(ticker):
    return _get(f"{BASE}/v3/reference/tickers/{ticker}").get("results",{}) or {}

def classify_mc(market_cap):
    try:
        if market_cap is None: return None
        mc = float(market_cap);
        if not (mc > 0): return None
    except Exception:
        return None
    B = 1_000_000_000; M = 1_000_000
    if mc >= 200*B: return "Mega"
    if mc >= 10*B:  return "Large"
    if mc >= 2*B:   return "Mid"
    if mc >= 300*M: return "Small"
    if mc >= 50*M:  return "Micro"
    return "Nano"

# === æ‰¹æ¬¡æ˜¨æ”¶ ===
def _most_recent_mkt_day():
    return (date.today() - timedelta(days=1)).strftime("%Y-%m-%d")

@lru_cache(maxsize=2)
def prev_close_map_for_all(group_day: str | None = None):
    day = group_day or _most_recent_mkt_day()
    url = f"{BASE}/v2/aggs/grouped/locale/us/market/stocks/{day}"
    js = _get(url, {"adjusted": "true"})
    mp = {}
    for r in js.get("results", []) or []:
        t = r.get("T") or r.get("ticker")
        c = r.get("c")
        if t and c is not None:
            mp[t] = float(c)
    return mp

def last_close_fast(ticker, mp=None):
    if mp and ticker in mp:
        return mp[ticker]
    js = _get(f"{BASE}/v2/aggs/ticker/{ticker}/prev")
    arr = js.get("results", [])
    return (arr[0]["c"] if arr else None)

"""Cell 2P â€” å­£åº¦å·¥å…· + è‚¡åˆ©åºåˆ— / TTM / 3 å¹´ 12 æ¬¡ / DGEï¼ˆEPS ç”± Cell 3 æä¾›ï¼‰"""

# Quarter helpers
def _quarter_of(d: date) -> int: return (d.month - 1) // 3 + 1
def _quarter_start(d: date) -> date:
    m = ((d.month - 1) // 3) * 3 + 1; return date(d.year, m, 1)
def _quarter_end(d: date) -> date:
    qs = _quarter_start(d); nxt = date(qs.year + (1 if qs.month == 10 else 0), (1 if qs.month == 10 else qs.month + 3), 1)
    return nxt - relativedelta(days=1)
def _is_same_quarter(d1: date, d2: date) -> bool: return _quarter_start(d1) == _quarter_start(d2)

# æœ€è¿‘ä¸€ç­†å››æ—¥æœŸï¼ˆæœªä¾†å„ªå…ˆï¼‰
def pick_div_dates(ticker):
    today = date.today()
    js = _get(f"{BASE}/v3/reference/dividends", {
        "ticker": ticker,
        "ex_dividend_date.gte": (today - relativedelta(years=3)).isoformat(),
        "ex_dividend_date.lte": (today + relativedelta(years=1)).isoformat(),
        "limit": 1000, "order": "asc", "sort": "ex_dividend_date"
    })
    divs = js.get("results", [])
    def to_d(s):
        try: return date.fromisoformat(s)
        except: return None
    for r in divs: r["_ex"] = to_d(r.get("ex_dividend_date"))
    up  = [r for r in divs if r.get("_ex") and r["_ex"] >= today]
    past= [r for r in divs if r.get("_ex") and r["_ex"] <  today]
    ch = (sorted(up, key=lambda r:r["_ex"])[0] if up else (sorted(past, key=lambda r:r["_ex"], reverse=True)[0] if past else None))
    return {
        "Declaration Date": ch.get("declaration_date") if ch else None,
        "Ex-Dividend Date": ch.get("ex_dividend_date") if ch else None,
        "Record Date":      ch.get("record_date")      if ch else None,
        "Pay Date":         ch.get("pay_date")         if ch else None,
    }

# è‚¡åˆ©äº‹ä»¶ï¼ˆå¿«å–ï¼‰
@lru_cache(maxsize=50_000)
def _div_events_cached(ticker, use_pay_date: bool, years: int):
    today = date.today()
    start = today - relativedelta(years=years)
    date_field = "pay_date" if use_pay_date else "ex_dividend_date"
    url = f"{BASE}/v3/reference/dividends"
    params = {
        "ticker": ticker,
        f"{date_field}.gte": start.isoformat(),
        f"{date_field}.lte": (_quarter_end(today)).isoformat(),
        "order": "asc", "sort": date_field, "limit": 1000,
    }
    out = []
    js = _get(url, params); out += js.get("results", [])
    while js.get("next_url"):
        nxt = js["next_url"]; url = nxt.split("?")[0]
        params = {kv.split("=")[0]: kv.split("=")[1] for kv in nxt.split("?")[1].split("&") if not kv.startswith("apiKey=")}
        js = _get(url, params); out += js.get("results", [])
    return tuple(out)

def polygon_div_series(ticker, use_pay_date=False, include_special=False, years=LOOKBACK_YEARS_DIV):
    evs = list(_div_events_cached(ticker, use_pay_date, years))
    rows=[]
    for ev in evs:
        try:
            if ev.get("currency") != "USD":
                continue
            if not include_special and (ev.get("dividend_type") or "").upper() not in ("CD", ""):
                continue
            dstr = ev.get("pay_date" if use_pay_date else "ex_dividend_date")
            if not dstr: continue
            dt = date.fromisoformat(dstr)
            amt = float(ev.get("cash_amount", 0.0) or 0.0)
            if amt <= 0: continue
            rows.append((dt, amt))
        except: continue
    if not rows: return pd.Series(dtype=float)
    s = pd.Series([v for _,v in rows], index=[d for d,_ in rows], dtype=float).sort_index()
    s.index = pd.to_datetime(s.index).date
    return s

def _sum_quarter_series(series: pd.Series, year: int, q: int, until: date = None):
    if series is None or series.empty: return 0.0
    start_m = (q-1)*3 + 1; end_m = start_m + 2
    qs = date(year, start_m, 1)
    qe = date(year + (1 if end_m==12 else 0), (1 if end_m==12 else end_m+1), 1) - relativedelta(days=1)
    if until and _is_same_quarter(qs, until): qe = min(qe, until)
    vals = [v for dt, v in series.items() if (qs <= dt <= qe)]
    return float(sum(vals)) if vals else 0.0

def _has_exdate_in_quarter(series: pd.Series, year: int, q: int) -> bool:
    if series is None or series.empty: return False
    start_m = (q-1)*3 + 1; end_m = start_m + 2
    qs = date(year, start_m, 1); qe = date(year + (1 if end_m==12 else 0), (1 if end_m==12 else end_m+1), 1) - relativedelta(days=1)
    for dt in series.index:
        if qs <= dt <= qe: return True
    return False

# TTMï¼ˆex-date 4Q æ³•ï¼›ä»ä¿ç•™åšè¼¸å‡ºï¼Œä½†æ®–åˆ©ç‡æ”¹èµ° ratios.dividend_yieldï¼‰
def dps_ttm_by_exdate_4q(ticker, use_pay_date=False, include_special=False, today=None):
    today = today or date.today()
    s = polygon_div_series(ticker, use_pay_date=use_pay_date, include_special=include_special, years=LOOKBACK_YEARS_DIV)
    y, q = today.year, _quarter_of(today)
    if _has_exdate_in_quarter(s, y, q):
        total = _sum_quarter_series(s, y, q)
        yy, qq = y, q-1
        if qq == 0: yy -= 1; qq = 4
        for _ in range(3):
            total += _sum_quarter_series(s, yy, qq); qq -= 1
            if qq == 0: yy -= 1; qq = 4
    else:
        yy, qq = y, q-1
        if qq == 0: yy -= 1; qq = 4
        total = 0.0
        for _ in range(4):
            total += _sum_quarter_series(s, yy, qq); qq -= 1
            if qq == 0: yy -= 1; qq = 4
    return (s, total if total > 0 else None)

# 3*365 å¤©ï¼ˆåªç®— CDï¼‰
def polygon_count_cash_dividends_last_3y_days(ticker, days=365*3):
    s = _div_events_cached(ticker, False, LOOKBACK_YEARS_DIV)
    today = date.today(); start = today - timedelta(days=days)
    cnt=0
    for r in s:
        if (r.get("dividend_type") or "").upper() == "CD":
            ex = r.get("ex_dividend_date")
            if ex:
                d = _to_date(ex)
                if d and start <= d <= today:
                    cnt += 1
    return cnt

# DGEï¼š7 å­£çª—ï¼Œé€£ 5 å­£ EPS > DPS æ‰åˆ¤ Nï¼ˆEPS ç”± Cell3ï¼‰
def dividend_ge_earnings_5q_strict_within7_polygon(
    ticker, use_pay_date: bool = False, include_special: bool = False, today: date | None = None,
) -> str:
    today = today or date.today()
    s = polygon_div_series(ticker, use_pay_date=use_pay_date, include_special=include_special, years=LOOKBACK_YEARS_DIV)
    eps_map = polygon_is_quarterly_eps_map(ticker, limit=16)  # from Cell3

    quarters = []; y, q = today.year, _quarter_of(today)
    for _ in range(7):
        quarters.append((y, q)); q -= 1
        if q == 0: y -= 1; q = 4

    start_idx = None
    for i, (yy, qq) in enumerate(quarters):
        eps = eps_map.get((yy, qq)); dps = _sum_quarter_series(s, yy, qq)
        if (eps is not None) and (dps is not None):
            start_idx = i; break
    if start_idx is None: return "Y"
    end_idx = start_idx + 4
    if end_idx >= len(quarters): return "Y"

    for j in range(start_idx, end_idx + 1):
        yy, qq = quarters[j]; eps = eps_map.get((yy, qq)); dps = _sum_quarter_series(s, yy, qq)
        if eps is None or dps is None: return "Y"
        if not (eps > dps): return "Y"
    return "N"

"""Cell 3 â€” Financialsï¼ˆBalance Sheets / Income Statements / Ratiosï¼Œå…¨ Polygonï¼›å«å¿«å–èˆ‡ä¼ºæœç«¯éæ¿¾ï¼‰"""

def _pick_fin_value(obj, path_flat, path_nested):
    # å„ªå…ˆæ‰å¹³ï¼›å†å˜—è©¦å·¢ç‹€
    if path_flat in obj and obj[path_flat] is not None:
        try: return float(obj[path_flat])
        except: pass
    cur = obj
    try:
        for k in path_nested: cur = cur.get(k, {})
        if cur is not None: return float(cur)
    except: pass
    return None

def _pick_date(obj):
    for k in ("period_end","period_of_report_date","end_date","fiscal_period_end_date","reporting_date"):
        if obj.get(k):
            d = _to_date(obj[k]);
            if d: return d
    return None

# ==== Balance Sheets (Quarterly; by ticker) ====
@lru_cache(maxsize=50_000)
def polygon_bs_quarterly_map(ticker: str) -> Dict[Tuple[int,int], Dict[str, Optional[float]]]:
    url  = f"{BASE}/stocks/financials/v1/balance-sheets"
    fy_gte = date.today().year - LOOKBACK_YEARS_BS
    rows = _paged(url, {
        "tickers": ticker,                # é‡è¦ï¼štickersï¼ˆè¤‡æ•¸ï¼‰
        "timeframe": "quarterly",
        "fiscal_year.gte": fy_gte,
        "limit": 2000,
        "sort": "period_end.asc"
    })
    out = {}
    for r in rows:
        # äºŒæ¬¡éæ¿¾ä¿éšª
        tk_list = r.get("tickers") or []
        if tk_list and ticker not in tk_list:
            continue
        y = r.get("fiscal_year"); q = r.get("fiscal_quarter")
        if not y or not q: continue
        dt = _pick_date(r)
        eq = _pick_fin_value(r, "total_equity", ["financials","balance_sheet","total_equity","value"])
        db = _pick_fin_value(r, "long_term_debt_and_capital_lease_obligations",
                                ["financials","balance_sheet","long_term_debt_and_capital_lease_obligations","value"])
        out[(int(y), int(q))] = {"total_equity": eq, "long_term_debt_and_capital_lease_obligations": db, "label_date": dt}
    return out

def polygon_bs_annual_q4(ticker: str, years: Tuple[int,int]) -> Dict[int, Tuple[Optional[float], Optional[float]]]:
    mp  = polygon_bs_quarterly_map(ticker)
    out = {}
    for y in years:
        v = mp.get((y,4)); out[y] = (v.get("total_equity"), v.get("long_term_debt_and_capital_lease_obligations")) if v else (None, None)
    return out

def polygon_bs_latest_quarter(ticker: str) -> Tuple[Optional[str], Optional[float], Optional[float]]:
    mp = polygon_bs_quarterly_map(ticker)
    if not mp: return (None, None, None)
    y,q = sorted(mp.keys())[-1]; v = mp[(y,q)]
    lab = f"{y}Q{q}"
    return (lab, v.get("total_equity"), v.get("long_term_debt_and_capital_lease_obligations"))

# ==== Income Statements (Quarterly EPS; by ticker) ====
@lru_cache(maxsize=50_000)
def polygon_is_quarterly_eps_map(ticker: str, limit: int = 16) -> Dict[Tuple[int,int], float]:
    url  = f"{BASE}/stocks/financials/v1/income-statements"
    fy_gte = date.today().year - LOOKBACK_YEARS_EPS
    rows = _paged(url, {
        "tickers": ticker,
        "timeframe": "quarterly",
        "fiscal_year.gte": fy_gte,
        "limit": 2000,
        "sort": "period_end.asc"
    })
    eps_map = {}
    for r in rows:
        tk_list = r.get("tickers") or []
        if tk_list and ticker not in tk_list:
            continue
        y = r.get("fiscal_year"); q = r.get("fiscal_quarter")
        if not y or not q: continue
        eps = _pick_fin_value(r, "basic_earnings_per_share",
                                 ["financials","income_statement","basic_earnings_per_share","value"])
        if eps is not None:
            eps_map[(int(y), int(q))] = float(eps)
    if len(eps_map) > limit:
        keys = sorted(eps_map.keys())[-limit:]
        eps_map = {k: eps_map[k] for k in keys}
    return eps_map

# ==== Ratiosï¼ˆEPS_TTM / P-E / Dividend Yieldï¼›by tickerï¼‰====
def _to_percent(v):
    try:
        if v is None: return None
        f = float(v)
        # docs sampleé¡¯ç¤º 0.0044 â‰ˆ 0.44%ï¼Œå› æ­¤ <=1.0 è¦–ç‚ºæ¯”ä¾‹ã€è½‰ç™¾åˆ†æ¯”
        return f*100.0 if f <= 1.0 else f
    except:
        return None

@lru_cache(maxsize=50_000)
def polygon_ratios_latest(ticker: str) -> Dict[str, Optional[float]]:
    url  = f"{BASE}/stocks/financials/v1/ratios"
    rows = _paged(url, {"tickers": ticker, "order": "desc", "limit": 20})
    for r in rows:
        ok = False
        if isinstance(r.get("tickers"), list):
            ok = (ticker in r["tickers"])
        elif isinstance(r.get("ticker"), str):
            ok = (r["ticker"] == ticker)
        else:
            ok = True
        if not ok:
            continue
        eps_ttm = _pick_fin_value(r, "earnings_per_share", ["financials","ratios","earnings_per_share","value"])
        pe      = _pick_fin_value(r, "price_to_earnings", ["financials","ratios","price_to_earnings","value"])
        dy      = _pick_fin_value(r, "dividend_yield",   ["financials","ratios","dividend_yield","value"])
        return {"EPS_TTM": eps_ttm, "PE": pe, "DIV_YIELD_PCT": _to_percent(dy)}
    return {"EPS_TTM": None, "PE": None, "DIV_YIELD_PCT": None}

"""Cell 4 â€” è¦å‰‡ï¼ˆEquity/Debt åš´æ ¼ã€DGEï¼‰"""

def equity_debt_flags_strict_polygon(ticker: str):
    """
    å¹´å ±ï¼ˆè©²å¹´Q4ï¼‰ï¼šEquity_{å»å¹´} > Equity_{å‰å¹´} AND Debt_{å»å¹´} < Debt_{å‰å¹´}
    æœ€æ–°å­£ vs å»å¹´ï¼š  Equity_LatestQ > Equity_{å»å¹´} AND Debt_LatestQ < Debt_{å»å¹´}
    å…¨éƒ¨æ»¿è¶³ â†’ ("Y","Y")ï¼›å¦å‰‡ ("N","N")
    """
    y1, y2 = TARGET_YEAR, TARGET_YEAR-1
    ann = polygon_bs_annual_q4(ticker, years=(y2, y1))
    if (y1 not in ann) or (y2 not in ann): return "N","N"
    eq1, db1 = ann[y1]; eq2, db2 = ann[y2]
    if None in (eq1, db1, eq2, db2): return "N","N"
    if not (eq1 > eq2 and db1 < db2): return "N","N"

    lab, eq_q, db_q = polygon_bs_latest_quarter(ticker)
    if None in (eq_q, db_q): return "N","N"
    if not (eq_q > eq1 and db_q < db1): return "N","N"
    return "Y","Y"

"""Cell 5 â€” é™¤éŒ¯åˆ—ï¼ˆdebugï¼‰"""

def last_7q_keys_today():
    today = date.today(); y, q = today.year, _quarter_of(today)
    keys=[];
    for _ in range(7):
        keys.append((y,q)); q -= 1
        if q==0: y-=1; q=4
    return keys

def collect_all_inputs_for_debug(ticker, PREV=None):
    row = OrderedDict()
    row["Symbol"] = ticker

    ref = get_ref(ticker) or {}
    row["Company"]  = ref.get("name")
    row["Sector"]   = ref.get("sic_sector")
    row["Industry"] = ref.get("sic_description")
    row["Market Cap"] = ref.get("market_cap")
    row["Market Cap Class"] = classify_mc(ref.get("market_cap"))

    px = last_close_fast(ticker, PREV)
    row["Price"] = round(px, 4) if px else None

    # DPS (TTM) â€” ä»é¡¯ç¤º
    poly_series, d4q = dps_ttm_by_exdate_4q(ticker, use_pay_date=False, include_special=False)
    row["DPS (TTM)"] = round(d4q, 6) if d4q is not None else None

    # Ratiosï¼ˆEPS_TTM / P-E / Dividend Yieldï¼‰
    rat = polygon_ratios_latest(ticker)
    row["EPS (TTM)"]              = rat.get("EPS_TTM")
    row["P/E"]                    = rat.get("PE")
    row["Dividend Yield TTM (%)"] = rat.get("DIV_YIELD_PCT")
    row["Institutions (%)"]       = None

    # Equity/Debt å¹´å ±/å­£å ±
    y1, y2 = TARGET_YEAR, TARGET_YEAR-1
    ann = polygon_bs_annual_q4(ticker, years=(y2, y1))
    eq_y2 = db_y2 = eq_y1 = db_y1 = None
    if y2 in ann: eq_y2, db_y2 = ann[y2]
    if y1 in ann: eq_y1, db_y1 = ann[y1]
    row[f"Equity_{y2}"] = eq_y2; row[f"Debt_{y2}"] = db_y2
    row[f"Equity_{y1}"] = eq_y1; row[f"Debt_{y1}"] = db_y1

    qlab, eq_q, db_q = polygon_bs_latest_quarter(ticker)
    row["Latest Quarter Label"] = qlab
    row["Equity_LatestQ"] = eq_q; row["Debt_LatestQ"] = db_q

    row["Annual_Equity_Up(y1>y2)"] = (eq_y1 is not None and eq_y2 is not None and eq_y1 > eq_y2)
    row["Annual_Debt_Down(y1<y2)"] = (db_y1 is not None and db_y2 is not None and db_y1 < db_y2)
    row["Q_vs_Y1_Equity_Up"]       = (eq_q is not None and eq_y1 is not None and eq_q > eq_y1)
    row["Q_vs_Y1_Debt_Down"]       = (db_q is not None and db_y1 is not None and db_q < db_y1)

    # æœ€è¿‘ 7 å­£ EPS / åŒå­£ DPS
    eps_map = polygon_is_quarterly_eps_map(ticker, limit=16)
    for (yy, qq) in last_7q_keys_today():
        eps = eps_map.get((yy,qq))
        dps = _sum_quarter_series(poly_series, yy, qq) if isinstance(poly_series, pd.Series) else None
        row[f"EPS_{yy}Q{qq}"] = eps
        row[f"DPS_{yy}Q{qq}"] = round(dps, 6) if dps is not None else None

    # DGEï¼ˆPolygon ç‰ˆï¼‰
    dge = dividend_ge_earnings_5q_strict_within7_polygon(ticker, use_pay_date=False, include_special=False)
    row["Dividend â‰¥ Earnings (5Q)"] = dge

    # 3y CD count
    cd_cnt_3y_days = polygon_count_cash_dividends_last_3y_days(ticker, days=365*3)
    row["Cash Dividends (3y, days, Polygon)"] = cd_cnt_3y_days

    # è‚¡åˆ©æ—¥æœŸ
    dates = pick_div_dates(ticker)
    row["Declaration Date"] = dates.get("Declaration Date")
    row["Ex-Dividend Date"] = dates.get("Ex-Dividend Date")
    row["Record Date"]      = dates.get("Record Date")
    row["Pay Date"]         = dates.get("Pay Date")
    return row

"""Cell 6 â€” æ­£å¼æƒæï¼ˆå«ææ—©çµ‚æ­¢ã€åˆ†æ®µå­˜æª”ï¼‰"""

def process_one_with_reason_and_inputs_v2(ticker, PREV=None):
    row = OrderedDict()
    row["Symbol"] = ticker

    # å…ˆæ‹¿åƒ¹ï¼ˆæ‰¹æ¬¡ mapï¼‰
    px = last_close_fast(ticker, PREV)
    if not px or px <= 0:
        row["Price"] = None
        row["Fail Reason"] = "No price"
        return row
    row["Price"] = round(px, 4)

    # å…ˆåšã€Œä¾¿å®œä¸”é—œéµã€çš„å…©ä»¶äº‹ï¼š3y æ¬¡æ•¸ & ratios çš„æ®–åˆ©ç‡
    cd_cnt_3y_days = polygon_count_cash_dividends_last_3y_days(ticker, days=365*3)
    rat = polygon_ratios_latest(ticker)
    yld_pct = rat.get("DIV_YIELD_PCT")  # é€™å°±æ˜¯ä½ çš„ Dividend Yield TTM (%)

    row["Cash Dividends (3y, days, Polygon)"] = cd_cnt_3y_days
    row["Dividend Yield TTM (%)"] = yld_pct

    if (cd_cnt_3y_days is None) or (cd_cnt_3y_days < 12):
        row["Fail Reason"] = "Not â‰¥12 cash dividends (3y, days)"
        if FAST_EARLY_EXIT: return row

    if yld_pct is None:
        row["Fail Reason"] = "No dividend_yield (ratios)"
        if FAST_EARLY_EXIT: return row
    if (yld_pct < YIELD_MIN) or (yld_pct > YIELD_MAX):
        row["Fail Reason"] = f"Yield {yld_pct:.2f}% out of range"
        if FAST_EARLY_EXIT: return row

    # è£œé½Šå…¬å¸åŸºæœ¬è³‡è¨Š
    ref = get_ref(ticker) or {}
    row["Company"]   = ref.get("name")
    row["Industry"]  = ref.get("sic_description")
    row["Market Cap"] = ref.get("market_cap")
    row["Market Cap Class"] = classify_mc(ref.get("market_cap"))

    # DPS (TTM) â€” ç”¨æ–¼è¼¸å‡ºèˆ‡ DGE
    poly_series, d4q = dps_ttm_by_exdate_4q(ticker, use_pay_date=False, include_special=False)
    row["DPS (TTM)"] = round(d4q,6) if d4q is not None else None

    # å¹´å ±/å­£å ±ï¼ˆbalance sheetsï¼‰
    y1, y2 = TARGET_YEAR, TARGET_YEAR-1
    ann = polygon_bs_annual_q4(ticker, years=(y2, y1))
    eq_y2 = db_y2 = eq_y1 = db_y1 = None
    if y2 in ann: eq_y2, db_y2 = ann[y2]
    if y1 in ann: eq_y1, db_y1 = ann[y1]
    row[f"Equity_{y2}"] = eq_y2; row[f"Debt_{y2}"] = db_y2
    row[f"Equity_{y1}"] = eq_y1; row[f"Debt_{y1}"] = db_y1
    qlab, eq_q, db_q = polygon_bs_latest_quarter(ticker)
    row["Latest Quarter Label"] = qlab
    row["Equity_LatestQ"] = eq_q; row["Debt_LatestQ"] = db_q
    row["Annual_Equity_Up(y1>y2)"] = (eq_y1 is not None and eq_y2 is not None and eq_y1 > eq_y2)
    row["Annual_Debt_Down(y1<y2)"] = (db_y1 is not None and db_y2 is not None and db_y1 < db_y2)
    row["Q_vs_Y1_Equity_Up"]       = (eq_q is not None and eq_y1 is not None and eq_q > eq_y1)
    row["Q_vs_Y1_Debt_Down"]       = (db_q is not None and db_y1 is not None and db_q < db_y1)

    eq_flag, db_flag = equity_debt_flags_strict_polygon(ticker)
    row["Equity Up"] = eq_flag; row["Debt Down"] = db_flag
    if (eq_flag, db_flag) != ("Y","Y"):
        row["Fail Reason"] = "Equity/ Debt rule fail"

    # EPS/DGEï¼ˆ7 å­£çª—ï¼‰
    eps_map = polygon_is_quarterly_eps_map(ticker, limit=16)
    yy, qq = date.today().year, _quarter_of(date.today())
    keys7=[]
    for _ in range(7):
        keys7.append((yy,qq)); qq -= 1
        if qq==0: yy -= 1; qq = 4
    for (yy, qq) in keys7:
        eps = eps_map.get((yy,qq))
        dps = _sum_quarter_series(poly_series, yy, qq) if isinstance(poly_series, pd.Series) else None
        row[f"EPS_{yy}Q{qq}"] = eps
        row[f"DPS_{yy}Q{qq}"] = round(dps, 6) if dps is not None else None

    dge = dividend_ge_earnings_5q_strict_within7_polygon(ticker, use_pay_date=False, include_special=False)
    row["Dividend Above Earnings (5Q)"] = dge
    if dge == "Y":
        row["Fail Reason"] = "Dividend Above Earnings (5Q)"

    # è‚¡åˆ©æ—¥æœŸ
    dates = pick_div_dates(ticker)
    row["Declaration Date"] = dates.get("Declaration Date")
    row["Ex-Dividend Date"] = dates.get("Ex-Dividend Date")
    row["Record Date"]      = dates.get("Record Date")
    row["Pay Date"]         = dates.get("Pay Date")

    # Ratiosï¼ˆè£œé½Š EPS_TTM / P-Eï¼›æ®–åˆ©ç‡å‰é¢å·²å¡«ï¼‰
    row["EPS (TTM)"]        = rat.get("EPS_TTM")
    row["P/E"]              = rat.get("PE")

    # P/EGï¼šP/E Ã· EPS(TTM)
    pe_val   = row.get("P/E"); eps_ttm  = row.get("EPS (TTM)")
    row["P/EG"] = (round((pe_val/eps_ttm),4) if (pe_val and eps_ttm and eps_ttm>0) else None)

    row.setdefault("Fail Reason", "PASS")
    return row

import streamlit as st
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd
import time

def run_full_market_inputs_with_reason(
    outfile="full_market_inputs_with_reason.csv",
    part_every=1500,
    max_workers=MAX_WORKERS,
    skip_share_classes=True,
    tickers=None,
    limit=None
):
    """
    åŸ·è¡Œä¸»æµç¨‹ï¼Œä¸¦åœ¨ Streamlit ä¸­é¡¯ç¤ºéšæ®µé€²åº¦ã€‚
    """

    # ===============================
    # éšæ®µ 1ï¼šè¼‰å…¥è‚¡ç¥¨æ¸…å–®
    # ===============================
    with st.status("ğŸš€ Starting full market scan...", expanded=True) as status:
        st.write("Fetching stock list...")
        if tickers is None:
            syms = fetch_all_us_common()
            if skip_share_classes:
                syms = [
                    s for s in syms
                    if not any(s.endswith(f".{c}") for c in list("ABCDEFGHIJKLMNOPQRSTUVWXYZ"))
                ]
        else:
            syms = list(tickers)
            if skip_share_classes:
                syms = [
                    s for s in syms
                    if not any(s.endswith(f".{c}") for c in list("ABCDEFGHIJKLMNOPQRSTUVWXYZ"))
                ]

        if isinstance(limit, int) and limit > 0:
            syms = syms[:limit]

        total = len(syms)
        st.write(f"âœ… Got {total} tickers to process")

        # ===============================
        # éšæ®µ 2ï¼šè¼‰å…¥æ˜¨æ”¶åƒ¹å¿«å–
        # ===============================
        st.write("Fetching previous close prices...")
        PREV = prev_close_map_for_all()
        st.write("âœ… Price map ready")

        # ===============================
        # éšæ®µ 3ï¼šä¸¦è¡Œè™•ç†è‚¡ç¥¨
        # ===============================
        st.write("Running threaded scan...")
        rows = []
        t0 = time.time()
        progress = st.progress(0, text="Starting scan...")
        processed = 0

        with ThreadPoolExecutor(max_workers=max_workers) as ex:
            futs = {ex.submit(process_one_with_reason_and_inputs_v2, s, PREV): s for s in syms}
            for i, f in enumerate(as_completed(futs), 1):
                s = futs[f]
                try:
                    r = f.result()
                    if r:
                        rows.append(r)
                except Exception as e:
                    st.write(f"[WARN] {s} error: {e}")

                # æ›´æ–°é€²åº¦åˆ—
                processed = i
                pct = int((processed / total) * 100)
                progress.progress(pct, text=f"Processed {processed}/{total} tickers ({pct}%)")

                # å®šæœŸè¼¸å‡ºéƒ¨åˆ†çµæœ
                if part_every and i % part_every == 0:
                    df_part = pd.DataFrame(rows)
                    path = f"{outfile}.part_{i}.csv"
                    df_part.to_csv(path, index=False, encoding="utf-8")
                    st.write(f"ğŸ’¾ Partial saved: {path} (rows={len(df_part)})")

        # ===============================
        # éšæ®µ 4ï¼šå„²å­˜å®Œæ•´çµæœ
        # ===============================
        st.write("Saving full CSV...")
        df = pd.DataFrame(rows)
        try:
            df.to_csv(outfile, index=False, encoding="utf-8")
            st.write(f"âœ… Saved full CSV: {outfile} | rows={len(df)}")
        except Exception as e:
            st.write(f"[ERROR] save full CSV: {e}")

        elapsed_min = (time.time() - t0) / 60
        st.write(f"â±ï¸ Total elapsed time: {elapsed_min:.1f} minutes")

        progress.progress(100, text="âœ… Completed all tasks")
        status.update(label="âœ… Full market scan completed successfully!", state="complete")

    return df


"""Cell 7 â€” å…ˆè·‘å‰ 10 æª”é©—è­‰ï¼Œå†è·‘å…¨å¸‚å ´"""

# ===============================
# åƒ…è·‘é€™30æª”ï¼ˆä¸è·‘å…¨å¸‚å ´ï¼‰
# ===============================
df_all = run_full_market_inputs_with_reason(
    outfile="full_market_inputs_with_reason_top30.csv",
    part_every=1500,
    max_workers=MAX_WORKERS,
    skip_share_classes=True,
    limit=10
)

try:
    display(df_all.head(10))
except:
    print(df_all.head(10))
print("ç¸½åˆ—æ•¸ï¼š", len(df_all))
